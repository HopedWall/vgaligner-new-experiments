{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c01497",
   "metadata": {},
   "source": [
    "# Comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "ALIGNERS = ['vgalignermap', 'graphaligner', 'graphchainer', 'vgmap', 'giraffe']\n",
    "\n",
    "# Functions\n",
    "## Crate the plot\n",
    "def my_plot(df, x, xlabel, ys, ylabel, title, legend):\n",
    "    plot = df.plot(x=x, y=ys, kind=\"bar\", title=title, legend=legend)\n",
    "    if legend:\n",
    "        plot.legend(loc=(1.04,0.75));\n",
    "    plot.set_xlabel(xlabel)\n",
    "    plot.set_ylabel(ylabel)\n",
    "    \n",
    "## Create and export plot to external file\n",
    "def my_plot_export(df, x, xlabel, ys, ylabel, title, file_name):\n",
    "    plot = my_plot(df, x, xlabel, columns_list, title, ylabel)\n",
    "    plot.get_figure().savefig(\"./plots/{}\".format(title))\n",
    "\n",
    "## Filter a df s.t. only those rows whose column having column_name is in values_list\n",
    "def drop_rows_with_seqnames(df, column_name, values_list):\n",
    "    new_df = df[~df[column_name].isin(values_list)]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [name for name in os.listdir(os.path.join(\".\",\"datasets\"))]\n",
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "for dataset in DATASETS:\n",
    "    results_folder = os.path.join(\".\",\"datasets\",dataset,\"results\")\n",
    "    \n",
    "    if os.path.exists(results_folder):\n",
    "        results_by_path = dict()\n",
    "        for name in os.listdir(results_folder):\n",
    "            name_without_ext = name[:-4]\n",
    "            path,aligner = name_without_ext.split('_')\n",
    "\n",
    "            if path not in results_by_path.keys():\n",
    "                results_by_path[path] = []\n",
    "            results_by_path[path].append((aligner,os.path.join(results_folder, name)))\n",
    "    \n",
    "    results[dataset] = results_by_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018f61b",
   "metadata": {},
   "source": [
    "# Q1: Which aligners worked and which didn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligners_results = []\n",
    "for dataset in DATASETS:\n",
    "    results_by_path = results[dataset]\n",
    "    for path in results_by_path.keys():\n",
    "        curr_record = dict()\n",
    "        curr_record['dataset'] = dataset\n",
    "        curr_record['path'] = path\n",
    "        curr_record['mapped by'] = set(map(lambda result : result[0], results_by_path[path]))\n",
    "        curr_record['not mapped by'] = set(ALIGNERS)-curr_record['mapped by']\n",
    "        curr_record['n aligner that worked'] = len(results_by_path[path])\n",
    "        curr_record['% aligner that worked'] = len(results_by_path[path])/len(ALIGNERS) * 100\n",
    "        aligners_results.append(curr_record)\n",
    "        # TODO: remove .gaf from vg map (in snakefile)\n",
    "       \n",
    "\n",
    "aligners_results_df = pd.DataFrame(aligners_results)\n",
    "group_by = aligners_results_df.groupby(['dataset','path'])\n",
    "group_by.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in aligners_results_df.groupby(\"dataset\"):\n",
    "    plot = my_plot(group, \"path\", \"path_name\", [\"n aligner that worked\"], \"n aligner\", \"Aligners that worked for {}\".format(name), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b00423",
   "metadata": {},
   "source": [
    "# Q2: How did the aligners perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe30fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aligners_performance = []\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    \n",
    "    logs_folder = os.path.join(\".\",\"datasets\",dataset, \"logs\")\n",
    "    if os.path.exists(logs_folder):\n",
    "        for name in os.listdir(logs_folder):\n",
    "\n",
    "            if not name.endswith(\".time\"):\n",
    "                continue\n",
    "\n",
    "            name_without_ext = name[:-5]\n",
    "\n",
    "            if name_without_ext == 'vgindex' or name_without_ext == \"vgaligner-index\":\n",
    "                continue\n",
    "            else:\n",
    "                path,aligner = name_without_ext.split('_')\n",
    "\n",
    "                log_full_path = os.path.join(logs_folder, name)\n",
    "                with open(log_full_path, \"r\") as fp:\n",
    "                    curr_record = dict()\n",
    "                    curr_record['dataset'] = dataset\n",
    "                    curr_record['aligner'] = aligner\n",
    "                    curr_record['path'] = name.split('_')[0]\n",
    "                    for line in fp.readlines():\n",
    "\n",
    "                        # TODO in the future: this could either be hh:mm:ss OR mm:ss.ms\n",
    "                        if line.lstrip().startswith(\"Elapsed (wall clock) time\"):\n",
    "                            elapsed_time_str = line.lstrip()[45:]\n",
    "                            curr_record['time'] = datetime.strptime(elapsed_time_str.strip(), '%M:%S.%f').time()\n",
    "\n",
    "                        if line.lstrip().startswith(\"Maximum resident set size\"):\n",
    "                            space = int(line.split(':')[1])\n",
    "                            curr_record['space (kbytes)']= space\n",
    "                            curr_record['space (mbytes)']= float(\"{:.2f}\".format(space/1000))\n",
    "\n",
    "                    aligners_performance.append(curr_record)\n",
    "    \n",
    "aligners_performance_df = pd.DataFrame(aligners_performance)\n",
    "group_by = aligners_performance_df.groupby(['dataset','path','aligner'])\n",
    "group_by.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c97ed",
   "metadata": {},
   "source": [
    "# Q3: Parse graphs stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cadaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = list()\n",
    "for dataset in DATASETS:\n",
    "    curr_graph_stats = dict()\n",
    "    curr_graph_stats[\"name\"] = dataset\n",
    "    \n",
    "    stats_file = os.path.join(\".\",\"datasets\",dataset, \"stats\", \"graph_stats.txt\".format(dataset))\n",
    "    with open(stats_file, \"r\") as fp:\n",
    "        for line in fp.readlines():\n",
    "            if line.startswith(\"nodes\"):\n",
    "                curr_graph_stats[\"nodes\"] = int(line.split(\"\\t\")[1])\n",
    "            elif line.startswith(\"edges\"):\n",
    "                curr_graph_stats[\"edges\"] = int(line.split(\"\\t\")[1])\n",
    "            elif line.startswith(\"self-loops\"):\n",
    "                curr_graph_stats[\"self-loops\"] = int(line.split(\"\\t\")[1])\n",
    "            else:\n",
    "                curr_graph_stats[\"cyclic\"] = True if line == \"cyclic\" else False\n",
    "    \n",
    "    graphs.append(curr_graph_stats)\n",
    "    \n",
    "graphs_df = pd.DataFrame(graphs)\n",
    "graphs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c405c03",
   "metadata": {},
   "source": [
    "# Q4: Parse comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f384f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_results = list()\n",
    "for dataset in DATASETS:\n",
    "    comparisons_folder = os.path.join(\".\",\"datasets\",dataset, \"comparisons\")\n",
    "    if os.path.exists(comparisons_folder):\n",
    "        for name in os.listdir(comparisons_folder):\n",
    "            name_without_ext = name[:-4]\n",
    "            path,aligner = name_without_ext.split('_')\n",
    "\n",
    "            curr_graph_stats = dict()\n",
    "            curr_graph_stats[\"name\"] = dataset\n",
    "\n",
    "            comparison_file = os.path.join(\".\",\"datasets\",dataset, \"comparisons\", name)\n",
    "            if os.path.exists(comparison_file):\n",
    "                with open(comparison_file, \"r\") as fp:\n",
    "                    for line in fp.readlines():\n",
    "                        if line.lstrip().startswith(\"Reads mapped correctly\"):\n",
    "                            _,value = line.lstrip().split(\":\")\n",
    "                            absolute, _ = value.lstrip().split(\" \")\n",
    "                            n_mapped, total_reads = absolute.split(\"/\")\n",
    "                            curr_result = {\n",
    "                                'name':dataset,\n",
    "                                'aligner':aligner,\n",
    "                                'path': path,\n",
    "                                'n_returned_alignments': int(total_reads),\n",
    "                                'n_correct_alignments':int(n_mapped),\n",
    "                                #'% correct': int(n_mapped)/int(total_reads)\n",
    "                            }\n",
    "                            break\n",
    "\n",
    "                jaccard_results.append(curr_result)\n",
    "\n",
    "jaccard_results_df = pd.DataFrame(jaccard_results)\n",
    "group_by = jaccard_results_df.groupby(['name','path','aligner'])\n",
    "group_by.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12817d9e",
   "metadata": {},
   "source": [
    "# Read analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results = list()\n",
    "for dataset in DATASETS:\n",
    "    comparisons_folder = os.path.join(\".\",\"datasets\",dataset, \"comparisons\")\n",
    "    if os.path.exists(comparisons_folder):\n",
    "        for name in os.listdir(comparisons_folder):\n",
    "            name_without_ext = name[:-4]\n",
    "            path,aligner = name_without_ext.split('_')\n",
    "\n",
    "            curr_graph_stats = dict()\n",
    "            curr_graph_stats[\"name\"] = dataset\n",
    "\n",
    "            comparison_file = os.path.join(\".\",\"datasets\",dataset, \"comparisons\", name)\n",
    "            \n",
    "            if os.path.exists(comparison_file):\n",
    "                with open(comparison_file, \"r\") as fp:\n",
    "                    lines = fp.readlines()\n",
    "                    for i in range(0, len(lines)):\n",
    "                        if lines[i].lstrip().startswith(\"Type\"):\n",
    "                            (line_is_correct, line_incorrect_aln_len, line_read_name, line_gaf_length, line_correct_length) = (lines[i].strip(), lines[i+1].strip(), lines[i+2].strip(), lines[i+3].strip(), lines[i+4].strip())\n",
    "\n",
    "                            is_correct = line_is_correct.split(\":\")[1].strip()\n",
    "                            incorrect_aln_len = line_incorrect_aln_len.split(\":\")[1].strip()\n",
    "                            read_name = line_read_name.split(\":\")[1].strip()\n",
    "                            gaf_length = line_gaf_length.split(\":\")[1].strip()\n",
    "                            correct_length = line_correct_length.split(\":\")[1].strip()\n",
    "\n",
    "                            curr_result = {\n",
    "                                'name':dataset,\n",
    "                                'aligner':aligner,\n",
    "                                'read_name':read_name,\n",
    "                                'is_correct': is_correct,\n",
    "                                \"incorrect_aln_len\": incorrect_aln_len,\n",
    "                                \"read_name\": read_name,\n",
    "                                \"gaf_length\": gaf_length,\n",
    "                                \"correct_length\": correct_length\n",
    "                            }\n",
    "                            read_results.append(curr_result)\n",
    "\n",
    "\n",
    "\n",
    "                    '''\n",
    "                    for line in fp.readlines():\n",
    "                        if line.lstrip().startswith(\"Read is\"):\n",
    "                            _,value = line.lstrip().split(\":\")\n",
    "                            read_name = value.strip()[1:]\n",
    "                            curr_result = {\n",
    "                                'name':dataset,\n",
    "                                'aligner':aligner,\n",
    "                                'read_name':read_name,\n",
    "                            }\n",
    "                            read_results.append(curr_result)\n",
    "                    '''\n",
    "\n",
    "#print(read_results)\n",
    "read_results_df = pd.DataFrame(read_results)\n",
    "read_results_df\n",
    "#group_by = read_results_df.groupby(['read_name'])\n",
    "#group_by.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ee971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
