import os

# First, find all of the provided datasets
# NOTE: under datasets there should be 1 folder for each graph. Each folder should ONLY contain a file named "graph.gfa" 
DATASETS = [name for name in os.listdir("./datasets")]

# For each dataset, we find all of its path with odgi paths (this is necessary because snakemake should know all of the
# paths in advance). We then create two lists FINAL_DATASETS and PATHS, s.t. we have pairs (graph_i, path_j_of_graph_i):
# FINAL_PATHS =    ["graph1",       "graph1",       "graph1",          "graph2",         "graph2",       ...]
# FINAL_DATASETS = ["graph1-path1", "graph1-path2", "graph1-path3",    "graph2-path1",   "graph2-path2", ...]
FINAL_DATASETS = []
PATHS = []
for dataset in DATASETS:
	graph_filename = os.path.join("./datasets", dataset, "graph.gfa")
	paths = os.popen("odgi paths -i {} -L".format(graph_filename)).read().split("\n")[:-1]
	FINAL_DATASETS.extend([dataset]*len(paths))
	PATHS.extend(paths)
assert(len(FINAL_DATASETS) == len(PATHS))

# Obtain a dict with key dataset_name and as values its paths
PATHS_PER_DATASET = dict()
for pos,dataset in enumerate(FINAL_DATASETS):
	curr_path = PATHS[pos]
	if dataset not in PATHS_PER_DATASET.keys():
		PATHS_PER_DATASET[dataset] = []
	PATHS_PER_DATASET[dataset].append(curr_path)

# Parameters for the analysis
kmersize = 11	# VG can't build GCSA2 index with kmer size > 16 (i.e. can't use 21 for comparisons)
threshold = 0.8

rule all:
	input:
		# Comparisons
		expand("datasets/{dataset}/comparisons/{path}_graphaligner.txt",zip,dataset=FINAL_DATASETS,path=PATHS),
		expand("datasets/{dataset}/comparisons/{path}_vgalignermap.txt",zip,dataset=FINAL_DATASETS, path=PATHS),
		expand("datasets/{dataset}/comparisons/{path}_vgmap.txt",zip,dataset=FINAL_DATASETS, path=PATHS),
		expand("datasets/{dataset}/comparisons/{path}_giraffe.txt",zip,dataset=FINAL_DATASETS,path=PATHS),
		expand("datasets/{dataset}/comparisons/{path}_graphchainer.txt",zip,dataset=FINAL_DATASETS, path=PATHS),
		# Graph stats
		expand("datasets/{dataset}/stats/graph_stats.txt", dataset=DATASETS)

##### Sort the graph #####
rule odgi_sort:
	input:
		"datasets/{dataset}/graph.gfa"
	output:
		"datasets/{dataset}/sorted_graph.gfa"
	threads: 8
	shell:
		"odgi sort -i {input} -o - -p Ygs -P -t {threads} | odgi view -i - -g -t {threads} > {output}"

#### Graph stats ####
rule graph_stats:
    input:
        "datasets/{dataset}/sorted_graph.gfa"
    output:
        "datasets/{dataset}/stats/graph_stats.txt"
    shell:
        "vg stats -zAL {input} > {output}"

'''
##### Split into connected components #####
rule odgi_explode:
	input:
		"datasets/{dataset}/sorted_starting_graph.gfa"
	output:
		"datasets/{dataset}/component.{i}.og"
	threads: 8
	shell:
		"odgi explode -i {input} -t {threads} -p datasets/{dataset}/component"

##### Convert .og into .gfa #####
rule odgi_convert:
	input:
		"datasets/{dataset}/component.0.og"
	output:
		"datasets/{dataset}/sorted_graph.gfa"
	shell:
		"odgi view -i {input} -g > {output}"
'''

##### Create a fasta file with all the paths #####
rule get_paths:
	input:
		"datasets/{dataset}/sorted_graph.gfa"
	output:
		"datasets/{dataset}/paths.fasta"
	shell:
		"odgi paths -i {input} -f > {output}"
'''
##### Split fasta into separate files #####
rule split_paths:
	input:
		"datasets/{dataset}/paths.fasta"
	output:
		#expand("datasets/{{dataset}}/paths/{path}.fa", path=PATHS)
		"datasets/{dataset}/paths/{path}.fa"
	shell:
		"awk -v prefix='datasets/{dataset}/paths/' -f scripts/split.awk {input}"
'''

rule split_paths:
    input:
        "datasets/{dataset}/paths.fasta"
    output:
        "datasets/{dataset}/paths/{path}.fa"
    params:
        name = "{path}"
    shell:
        """
        samtools faidx {input} '{params.name}' > '{output}'
        """

##### Read generation with pbsim #####
rule art_illumina_generate:
	input:
		"datasets/{dataset}/paths/{path}.fa"
	output:
		"datasets/{dataset}/reads/{path}_0001.fastq"
	params:
		length=150,
		coverage=10,
		prefix="datasets/{dataset}/reads/{path}_0001",
		fq="datasets/{dataset}/reads/{path}_0001.fq"
	shell:
		'''
		art_illumina -ss HS25 -sam -i '{input}' -l {params.length} -f {params.coverage} -o '{params.prefix}'
		mv '{params.fq}' '{output}'
		'''

##### Run vgaligner #####
rule vgaligner_index:
	input:
		"datasets/{dataset}/sorted_graph.gfa"
	output:
		index = "datasets/{dataset}/sorted_graph.idx",
		mappings = "datasets/{dataset}/mappings.json"
	threads: 8
	log:
		log = "datasets/{dataset}/logs/vgalignerindex.log",
		time = "datasets/{dataset}/logs/vgalignerindex.time"
	shell:
		'''
		/usr/bin/time -v -o '{log.time}' vgaligner index -i {input} -k {kmersize} -t {threads} -o {output.index} --generate-mappings 2> {log.log}
		mv mappings.json datasets/{dataset}/mappings.json
		'''

rule vgaligner_map:
	input:
		index = "datasets/{dataset}/sorted_graph.idx",
		reads = "datasets/{dataset}/reads/{path}_0001.fastq"
	output:
		"datasets/{dataset}/results/{path}_vgalignermap.gaf"
	threads: 8
	log:
		log = "datasets/{dataset}/logs/{path}_vgalignermap.log",
		time = "datasets/{dataset}/logs/{path}_vgalignermap.time"
	shell:
		"/usr/bin/time -v -o '{log.time}' vgaligner map -i {input.index} -f '{input.reads}' --also-align -t {threads} -o '{output}' 2> '{log.log}'"

##### Run VG #####
rule vg_convert_gfa_to_vg:
	input:
		"datasets/{dataset}/sorted_graph.gfa"
	output:
		"datasets/{dataset}/sorted_graph_temp.vg"
	shell:
		"vg convert -g {input} > {output}"

rule vg_mod:
	input:
		"datasets/{dataset}/sorted_graph_temp.vg"
	output:
		"datasets/{dataset}/sorted_graph.vg"
	shell:
		"vg mod -X 256 {input} > {output}"

rule vg_index:
	input: 
		"datasets/{dataset}/sorted_graph.vg"
	output:
		xg="datasets/{dataset}/sorted_graph.xg",
		gcsa="datasets/{dataset}/sorted_graph.gcsa"
	threads: 8
	log:
		time="datasets/{dataset}/logs/vgindex.time"
	shell:
		"/usr/bin/time -v -o {log.time} vg index {input} -x {output.xg} -g {output.gcsa} -k {kmersize} -t {threads}"

rule vg_map:
	input:
		"datasets/{dataset}/sorted_graph.xg",
		"datasets/{dataset}/sorted_graph.gcsa",
		reads="datasets/{dataset}/reads/{path}_0001.fastq"
	output:
		"datasets/{dataset}/results/{path}_vgmap.gaf"
	params:
		prefix="datasets/{dataset}/sorted_graph"
	threads: 8
	log:
		time="datasets/{dataset}/logs/{path}_vgmap.time"
	shell:
		"/usr/bin/time -v -o '{log.time}' vg map -d {params.prefix} -f '{input.reads}' -t {threads} --gaf > '{output}'"

'''
rule vg_map_convert:
	input: 
		gam="datasets/{dataset}/results/{path}_vgmap.gam",
		graph="datasets/{dataset}/sorted_graph.vg"
	output:
		"datasets/{dataset}/results/{path}_vgmap.gaf"
	shell:
		"vg convert --gam-to-gaf '{input.gam}' {input.graph} >'{output}'"
'''

##### Run graphaligner #####
rule graphaligner:
	input:
		graph="datasets/{dataset}/sorted_graph.gfa",
		reads="datasets/{dataset}/reads/{path}_0001.fastq"
	output:
		"datasets/{dataset}/results/{path}_graphaligner.gaf"
	threads: 8
	log:
		log="datasets/{dataset}/logs/{path}_graphaligner.log",
		time="datasets/{dataset}/logs/{path}_graphaligner.time"
	shell:
		"touch '{output}' && /usr/bin/time -v -o '{log.time}' GraphAligner -g {input.graph} -f '{input.reads}' -a '{output}' -x vg -t {threads} > '{log.log}'"

##### Run giraffe #####
# https://github.com/vgteam/vg/wiki/Mapping-short-reads-with-Giraffe

rule vg_autoindex:
	input:
		"datasets/{dataset}/sorted_graph.gfa"
	output:
		"datasets/{dataset}/index.dist",
		"datasets/{dataset}/index.gg",
		"datasets/{dataset}/index.giraffe.gbwt",
		"datasets/{dataset}/index.min"
	params:
		prefix="datasets/{dataset}/index"
	shell:
		"vg autoindex --workflow giraffe -g {input} -p {params.prefix}"

rule vg_giraffe:
	input:
		gbwt_index="datasets/{dataset}/index.giraffe.gbwt",
		gbwt_graph="datasets/{dataset}/index.gg",
		minimizer_index="datasets/{dataset}/index.min",
		dist_index="datasets/{dataset}/index.dist",
		reads="datasets/{dataset}/reads/{path}_0001.fastq"
	output:
		"datasets/{dataset}/results/{path}_giraffe.gaf"
	threads: 8
	log:
		log="datasets/{dataset}/logs/{path}_giraffe.log",
		time="datasets/{dataset}/logs/{path}_giraffe.time"
	shell:
		"/usr/bin/time -v -o '{log.time}' vg giraffe -H {input.gbwt_index} -g {input.gbwt_graph} -m {input.minimizer_index} -d {input.dist_index} -f '{input.reads}' -t {threads} -o gaf > '{output}'"

##### Run graphchainer #####
rule graphchainer:
	input:
		graph="datasets/{dataset}/sorted_graph.gfa",
		reads="datasets/{dataset}/reads/{path}_0001.fastq"
	output:
		"datasets/{dataset}/results/{path}_graphchainer.gaf"
	threads: 8
	log:
		log="datasets/{dataset}/logs/{path}_graphchainer.log",
		time="datasets/{dataset}/logs/{path}_graphchainer.time"
	shell:
		"touch '{output}' && /usr/bin/time -v -o '{log.time}' GraphChainer -g {input.graph} -f '{input.reads}' -a '{output}' -t {threads} > '{log.log}'"

##### Run comparison scripts #####
rule gamcompare_graphaligner:
	input:
		gaf="datasets/{dataset}/results/{path}_graphaligner.gaf",
		mappings="datasets/{dataset}/mappings.json"
	output:
		"datasets/{dataset}/comparisons/{path}_graphaligner.txt"
	shell:
		"python3 scripts/GAFMAFcomparison2.py '{input.gaf}' {input.mappings} '{wildcards.path}' {threshold} graphaligner > '{output}'"

rule gamcompare_vgaligner:
	input:
		gaf="datasets/{dataset}/results/{path}_vgalignermap.gaf",
		mappings="datasets/{dataset}/mappings.json"
	output:
		"datasets/{dataset}/comparisons/{path}_vgalignermap.txt"
	shell:
		"python3 scripts/GAFMAFcomparison2.py '{input.gaf}' {input.mappings} '{wildcards.path}' {threshold} vgaligner > '{output}'"

rule gamcompare_vgmap:
	input:
		gaf="datasets/{dataset}/results/{path}_vgmap.gaf",
		mappings="datasets/{dataset}/mappings.json"
	output:
		"datasets/{dataset}/comparisons/{path}_vgmap.txt"
	shell:
		"python3 scripts/GAFMAFcomparison2.py '{input.gaf}' {input.mappings} '{wildcards.path}' {threshold} graphaligner > '{output}'"

rule gamcompare_giraffe:
	input:
		gaf="datasets/{dataset}/results/{path}_giraffe.gaf",
		mappings="datasets/{dataset}/mappings.json"
	output:
		"datasets/{dataset}/comparisons/{path}_giraffe.txt"
	shell:
		"python3 scripts/GAFMAFcomparison2.py '{input.gaf}' {input.mappings} '{wildcards.path}' {threshold} graphaligner > '{output}'"

rule gamcompare_graphchainer:
	input:
		gaf="datasets/{dataset}/results/{path}_graphchainer.gaf",
		mappings="datasets/{dataset}/mappings.json"
	output:
		"datasets/{dataset}/comparisons/{path}_graphchainer.txt"
	shell:
		"python3 scripts/GAFMAFcomparison2.py '{input.gaf}' {input.mappings} '{wildcards.path}' {threshold} graphaligner > '{output}'"
